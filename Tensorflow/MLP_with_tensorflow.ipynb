{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Project Name: Offline Handwriting Recognition using Deep Larning\n",
    "  ### Author Name: Chetan Malhotra, 14SCSE101072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Feed Forward Neural Ntwork implemented using TensorFlow for handwritten digit recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to TensorFlow's official website, “TensorFlow is an open source software library for numerical computation using dataflow graphs. Nodes in the graph represents mathematical operations, while graph edges represent multi-dimensional data arrays (aka tensors) communicated between them. The flexible architecture allows us to deploy computation to one or more CPUs or GPUs in a desktop, server, or mobile device with a single API.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorflow](images/tensors_flowing-3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s easy to classify TensorFlow as a neural network library, but it’s not just that. Yes, it was designed to be a powerful neural network library. But it has the power to do much more than that. We can build other machine learning algorithms on it such as decision trees or k-Nearest Neighbors. We can literally do everything we normally would do in numpy! It’s aptly called “numpy on steroids” by the open-source community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The advantages of using TensorFlow are:\n",
    "\n",
    "1. It has an intuitive construct, because as the name suggests it has “flow of tensors”. \n",
    "2. we can easily visualize each and every part of the graph.\n",
    "3. Easily train on cpu/gpu for distributed computing\n",
    "4. Platform flexibility. We can run the models wherever we want, whether it is on mobile, server or PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The usual workflow of running a program in TensorFlow is as follows:\n",
    "\n",
    "1. Build a computational graph, this can be any mathematical operation TensorFlow supports.\n",
    "2. Initialize variables, to compile the variables defined previously\n",
    "3. Create session, this is where we start implementing the model or algorithm\n",
    "4. Run graph in session: the compiled graph is passed to the session, which starts its execution. \n",
    "5. Close session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before starting, few terminologies for tensorflow:\n",
    "\n",
    "* Placeholder-A way to feed data into the graphs\n",
    "* feed_dict-A dictionary to pass numeric values to computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get acquainted I am gonna write a program using tensorflow to add two numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 5\n"
     ]
    }
   ],
   "source": [
    "#importing tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#buiding a computational graph\n",
    "a=tf.placeholder(tf.int16)\n",
    "b=tf.placeholder(tf.int16)\n",
    "\n",
    "sum = tf.add(a,b)\n",
    "\n",
    "#initializing variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#starting the session and running the graph \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Sum: %i\" % sess.run(sum, feed_dict={a:2, b:3}))\n",
    "          \n",
    "#closing the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementig a Feed Forward Multi-Layer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron (MLP) is a class of feedforward artificial neural network. An MLP consists of at least three layers of nodes. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A typical implementation of a Neural Network is as follows:\n",
    "\n",
    "* Define Neural Network architecture to be compiled\n",
    "* Transfer data to your model\n",
    "* Under the hood, the data is first divided into batches, so that it can be ingested. The batches are first preprocessed, augmented and then fed into Neural Network for training\n",
    "* The model then gets trained incrementally\n",
    "* Display the accuracy for a specific number of timesteps\n",
    "* After training save the model for future use\n",
    "* Test the model on a new data and check how it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is handwritten digit recognition, to identify digits from a given 28 x 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['test', 'imread', 'seed']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "#importing all the modules\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread  #imread uses the Python Imaging Library (PIL) to read an image.\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 128 # To stop potential randomness\n",
    "range = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little about the dataset:\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the data\n",
    "train=pd.read_csv(os.path.join('data','Train','train.csv'))\n",
    "test=pd.read_csv(os.path.join('data','Test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of what our data looks li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will read the images from the data-set and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24d74320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = range.choice(train.filename)\n",
    "data_dir = os.path.join(root_dir, '8th-sem-project/TensorFlow/data')\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image is represented when represented using numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   23.,  172.,  213.,   89.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,   88.,  222.,  254.,  139.,    1.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   56.,  190.,  251.,  222.,   93.,    2.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   88.,  234.,  254.,  208.,   11.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          43.,  245.,  254.,  225.,   51.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   11.,\n",
       "         175.,  254.,  174.,   10.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   36.,\n",
       "         254.,  253.,   73.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  130.,\n",
       "         254.,  227.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   40.,  249.,\n",
       "         254.,   97.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   95.,  254.,\n",
       "         254.,   20.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   95.,  255.,\n",
       "         254.,   20.,    0.,    0.,    0.,    0.,    0.,    0.,   56.,\n",
       "         135.,  190.,  100.,   10.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   95.,  254.,\n",
       "         254.,   20.,    0.,    0.,    0.,    3.,  146.,  229.,  253.,\n",
       "         254.,  254.,  254.,  242.,   76.,    6.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   95.,  254.,\n",
       "         254.,   20.,    0.,    0.,    0.,  121.,  254.,  254.,  254.,\n",
       "         224.,  166.,  166.,  246.,  254.,  115.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   95.,  254.,\n",
       "         254.,   20.,    0.,    0.,   34.,  235.,  254.,  242.,   60.,\n",
       "          10.,    0.,    0.,   65.,  211.,  243.,   50.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   27.,  248.,\n",
       "         254.,  127.,    0.,    0.,   63.,  254.,  254.,  155.,    0.,\n",
       "           0.,    0.,    0.,    0.,  172.,  254.,   94.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,  142.,\n",
       "         254.,  241.,   47.,    0.,   32.,  234.,  254.,  163.,    1.,\n",
       "           0.,    0.,    0.,   28.,  213.,  241.,   48.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   27.,\n",
       "         237.,  254.,  231.,  172.,  104.,  225.,  254.,  254.,  113.,\n",
       "          68.,   68.,  142.,  246.,  254.,  113.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          60.,  237.,  254.,  254.,  254.,  254.,  254.,  254.,  254.,\n",
       "         254.,  254.,  254.,  245.,  146.,    5.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   10.,  123.,  197.,  235.,  254.,  254.,  254.,  254.,\n",
       "         254.,  254.,  237.,   20.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,   31.,   46.,   46.,   46.,  147.,\n",
       "         186.,  242.,  105.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ease of data manipulation, I will store all the images in form of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ebeddb89c99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create a validation set and will take a split size of 70:30 for train set vs validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_size=int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train.label.values[:split_size], train.label.values[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-f7de5b6b39e6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f7de5b6b39e6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Defining a method that converts class label\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Defining a method that converts class label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
